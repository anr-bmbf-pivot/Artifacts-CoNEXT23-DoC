# Data Collection Scripts for Empirical View on IoT DNS Traffic

This directory contains scripts to generate CSV files compatible with the scripts in
[`03-dns-empirical/plot`](../plot).

## Requirements
The scripts all were tested in Ubuntu 22.04. While the scripts should be possible to run in other
operating systems (especially the Python scripts), we do not guarantee successful execution.

All required python libraries are listed in [`requirements.txt`](./requirements.txt). They can be
installed using [pip] with the commands below.
We recommend installing them to a [Virtualenv] as shown, but it is not strictly necessary.

```sh
virtualenv env
. env/bin/activate
pip install -r requirements.txt
```

To generate the IXP data set, you also need [TShark], the [sFlow Toolkit] as well as access to the
collected samples of an IXP.

## Testing

The python scripts are tested for python versions 3.7 to 3.10 using [tox]. To test and lint the
code, run the following in this directory ([`03-dns-empirical/collect`](./)). If the python version
under test is installed, the tests for it will be executed.

```sh
tox
```

The [pytest] test cases can be found in the [`tests/`](./tests) directory.

## [`scan_iot_data.py`](./scan_iot_data.py)

`scan_iot_data.py` transforms the PCAP files provided by the [YourThings], [IoTFinder], and
[MonIoTr] studies into CSV files that can be parsed by the [Pandas] scripts in
[`03-dns-empirical/plot`](../plot). It expects either a tar file or a directory as input. Depending
on the source data set, the execution may take a long time.

```sh
./scan_iot_data.py ../results/iotfinder-iot-data/
# resulting CSV will be named ../results/iotfinder-iot-data.csv
./scan_iot_data.py ../results/moniotr-iot-data.tgz
# resulting CSV will be named ../results/moniotr-iot-data.tgz.csv
```

## [`run_parallel_ixp_dns.sh`](./run_parallel_ixp_dns.sh)

`run_parallel_ixp_dns.sh` transforms sampling data from an IXP to an intermediate, pseudonymized CSV
format. The IXP data is expected to be stored as PCAP files in `/mnt/data01/tcpdumpFiles`. The
location can be changed by modifying the `LOGDIR` environment variable.

The script only takes files that were modified between 2022-01-10 and 2022-01-17 (the second
calendar week of 2022) into account. For another time span, modify the `TS_START` and `TS_END`
environment variables. `TS_START` is the start date for the PCAPs and `TS_END` the last date for the
PCAPs to take into account.

```sh
LOGDIR=./myTCPdumps/ TS_START=2022-01-10 TS_END=2022-01-17 ./run_parallel_ixp_dns.sh
```

The resulting `.csv.gz` file will be stored to `dns_packets_ixp_2022_week.csv.gz`.

## [`reformat_dns_week_2022_2.py`](./reformat_dns_week_2022_2.py)

`reformat_dns_week_2022_2.py` will provide the IXP data generated with `run_parallel_ixp_dns.sh` in
a format that can be parsed by the [Pandas] scripts in [`03-dns-empirical/plot`](../plot). It
expects the `.csv.gz` file generated with `run_parallel_ixp_dns.sh` as input:

```sh
./reformat_dns_week_2022_2.py ./dns_packets_ixp_2022_week.csv.gz
```

The resulting `.csv.gz` file will be stored in `../results/dns_packets_ixp_2022_week.csv.gz`.

## [`count_names.sh`](./count_names.sh)

`count_names.sh` can be used to gauge the number unique of names in the CSV files generated by
[`scan_iot_data.py`](#scan_iot_datapy). It expects the CSV file as input and prints the number of
unique names with various filters to stdout.

[pip]: https://pip.pypa.io
[Virtualenv]: https://virtualenv.pypa.io
[TShark]: https://www.wireshark.org/docs/wsug_html_chunked/AppToolstshark.html
[sFlow Toolkit]: https://inmon.com/technology/sflowTools.php 
[tox]: https://tox.wiki
[pytest]: https://docs.pytest.org
[Pandas]: https://pandas.pydata.org/
[YourThings]: https://yourthings.info/data/#yourthings-data
[IoTFinder]: https://yourthings.info/data/#iotfinder-data
[MonIoTr]: https://moniotrlab.ccis.neu.edu/imc19/
